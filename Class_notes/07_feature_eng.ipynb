{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding categorical features\n",
    "\n",
    "#Be aware of sparse matrices !\n",
    "#Missing categorical values -> KNN :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf4685d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "provinces = [\"Wielkopolskie\", \"Pomorskie\", \"Lubuskie\", \"Slaskie\"]\n",
    "label_binarizer = LabelBinarizer()\n",
    "province_labels = label_binarizer.fit_transform(provinces)\n",
    "province_labels\n",
    "#label_binarizer.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49be78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lubuskie</th>\n",
       "      <th>Pomorskie</th>\n",
       "      <th>Slaskie</th>\n",
       "      <th>Wielkopolskie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lubuskie  Pomorskie  Slaskie  Wielkopolskie\n",
       "0         0          0        0              1\n",
       "1         0          1        0              0\n",
       "2         1          0        0              0\n",
       "3         0          0        1              0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(provinces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1796f342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wielkopolskie', 'Poznan'),\n",
       " ('Pomorskie', 'Gdansk'),\n",
       " ('Lubuskie', 'Lublin'),\n",
       " ('Slaskie', 'Katowice')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "cities = [\"Poznan\", \"Gdansk\", \"Lublin\", \"Katowice\"]\n",
    "provs_and_cities = list(zip(provinces, cities))\n",
    "provs_and_cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581b2eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_binarizer = MultiLabelBinarizer()\n",
    "multi_label_binarizer.fit_transform(provs_and_cities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding ordinal features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb5f72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orange</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banana</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit    size\n",
       "0   apple  medium\n",
       "1  orange   small\n",
       "2  banana   large"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([['apple', 'medium'],\n",
    "                   ['orange', 'small'], \n",
    "                   ['banana', 'large']], \n",
    "                  columns=[\"fruit\", \"size\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4d3daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orange</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banana</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit  size\n",
       "0   apple     2\n",
       "1  orange     1\n",
       "2  banana     3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {\"small\": 1,\n",
    "                \"large\": 3,\n",
    "                \"medium\": 2}\n",
    "# df['size'] = df['size'].map(mapping_dict)\n",
    "df['size'] = df['size'].replace(mapping_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ef5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescaling the data\n",
    "\n",
    "    #Log normalization np.log (check the columns variance)\n",
    "    #MinMaxScaler\n",
    "    #StandardScaler\n",
    "    #RobustScaler\n",
    "#To read:\n",
    "    #http://benalexkeen.com/feature-scaling-with-scikit-learn/\n",
    "    #https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zadania\n",
    "\n",
    "#1. Znajdź różnice pomiędzy LabelEncoder, OHE, LabelBinerizer\n",
    "#2. Zamień wartości w kolumnach tekstowych na typ integer. Zastanów się nad wyborem kolummn.\n",
    "#3. Przeprowadź skalowanie/standaryzację danych numerycznych (pomiń te z pkt.2) i sprawdź wyniki.\n",
    "#4. Sprawdź też jaki wpływ ma standaryzacja na KNN, wykorzystany przy uzupełnianiu brakujących danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4cde840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "houses = pd.read_csv('houses_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20cd9798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Regionname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>3/12/2016</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>h</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>40 Federation La</td>\n",
       "      <td>h</td>\n",
       "      <td>PI</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>55a Park St</td>\n",
       "      <td>h</td>\n",
       "      <td>VB</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>4/06/2016</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13575</th>\n",
       "      <td>Wheelers Hill</td>\n",
       "      <td>12 Strada Cr</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Barry</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South-Eastern Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13576</th>\n",
       "      <td>Williamstown</td>\n",
       "      <td>77 Merrett Dr</td>\n",
       "      <td>h</td>\n",
       "      <td>SP</td>\n",
       "      <td>Williams</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13577</th>\n",
       "      <td>Williamstown</td>\n",
       "      <td>83 Power St</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Raine</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13578</th>\n",
       "      <td>Williamstown</td>\n",
       "      <td>96 Verdon St</td>\n",
       "      <td>h</td>\n",
       "      <td>PI</td>\n",
       "      <td>Sweeney</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13579</th>\n",
       "      <td>Yarraville</td>\n",
       "      <td>6 Agnes St</td>\n",
       "      <td>h</td>\n",
       "      <td>SP</td>\n",
       "      <td>Village</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13580 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Suburb           Address Type Method   SellerG        Date  \\\n",
       "0         Abbotsford      85 Turner St    h      S    Biggin   3/12/2016   \n",
       "1         Abbotsford   25 Bloomburg St    h      S    Biggin   4/02/2016   \n",
       "2         Abbotsford      5 Charles St    h     SP    Biggin   4/03/2017   \n",
       "3         Abbotsford  40 Federation La    h     PI    Biggin   4/03/2017   \n",
       "4         Abbotsford       55a Park St    h     VB    Nelson   4/06/2016   \n",
       "...              ...               ...  ...    ...       ...         ...   \n",
       "13575  Wheelers Hill      12 Strada Cr    h      S     Barry  26/08/2017   \n",
       "13576   Williamstown     77 Merrett Dr    h     SP  Williams  26/08/2017   \n",
       "13577   Williamstown       83 Power St    h      S     Raine  26/08/2017   \n",
       "13578   Williamstown      96 Verdon St    h     PI   Sweeney  26/08/2017   \n",
       "13579     Yarraville        6 Agnes St    h     SP   Village  26/08/2017   \n",
       "\n",
       "      CouncilArea                  Regionname  \n",
       "0           Yarra       Northern Metropolitan  \n",
       "1           Yarra       Northern Metropolitan  \n",
       "2           Yarra       Northern Metropolitan  \n",
       "3           Yarra       Northern Metropolitan  \n",
       "4           Yarra       Northern Metropolitan  \n",
       "...           ...                         ...  \n",
       "13575         NaN  South-Eastern Metropolitan  \n",
       "13576         NaN        Western Metropolitan  \n",
       "13577         NaN        Western Metropolitan  \n",
       "13578         NaN        Western Metropolitan  \n",
       "13579         NaN        Western Metropolitan  \n",
       "\n",
       "[13580 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ed2d12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yarra', 'Moonee Valley', 'Port Phillip', 'Darebin', 'Hobsons Bay',\n",
       "       'Stonnington', 'Boroondara', 'Monash', 'Glen Eira', 'Whitehorse',\n",
       "       'Maribyrnong', 'Bayside', 'Moreland', 'Manningham', 'Banyule',\n",
       "       'Melbourne', 'Kingston', 'Brimbank', 'Hume', nan, 'Knox',\n",
       "       'Maroondah', 'Casey', 'Melton', 'Greater Dandenong', 'Nillumbik',\n",
       "       'Whittlesea', 'Frankston', 'Macedon Ranges', 'Yarra Ranges',\n",
       "       'Wyndham', 'Cardinia', 'Unavailable', 'Moorabool'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses.CouncilArea.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b7b3a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Northern Metropolitan', 'Western Metropolitan',\n",
       "       'Southern Metropolitan', 'Eastern Metropolitan',\n",
       "       'South-Eastern Metropolitan', 'Eastern Victoria',\n",
       "       'Northern Victoria', 'Western Victoria'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses.Regionname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e12c9973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "regionname = houses['Regionname']\n",
    "label_binarizer = LabelBinarizer()\n",
    "regionname_labels = label_binarizer.fit_transform(regionname)\n",
    "regionname_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "575866ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c294a0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Northern Metropolitan', 'Northern Victoria', 'Eastern Victoria']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(houses['Regionname'])\n",
    "LabelEncoder()\n",
    "list(le.classes_)\n",
    "le.transform(houses['Regionname'])\n",
    "list(le.inverse_transform([2, 3, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# + konweracja i linki z zooma\n",
    "\n",
    "czy tylko ja słyszę charczący i przerywający mikrofon Pana Michała?\n",
    "From Sławomir Kranc to Everyone:  11:51 AM\n",
    "tylko ty\n",
    "wszystko jest w porzadku\n",
    "From Iwona K to Everyone:  11:51 AM\n",
    "ja dobrze słyszę\n",
    "From astodolski@edu.cdv.pl to Everyone:  11:51 AM\n",
    "dobrze jest\n",
    "From Michał Klimas to Everyone:  11:57 AM\n",
    "From typing import List, Tuple\n",
    "def read_csv_file(file_name: str) -> pd.Dataframe:\n",
    "List[str], Tuple[int, str]\n",
    "From Andrzej Stawicki to Everyone:  12:10 PM\n",
    "ok\n",
    "From Michał Klimas to Everyone:  12:18 PM\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.median_absolute_deviation.html\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.clip.html\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.percentile.html\n",
    "From Sławomir Kranc to Everyone:  12:21 PM\n",
    "ok to działamy\n",
    "From Michał Klimas to Everyone:  12:49 PM\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html\n",
    "& |\n",
    "From Michał Klimas to Everyone:  12:59 PM\n",
    "https://www.coursera.org/learn/machine-learning\n",
    "From Michał Klimas to Everyone:  01:06 PM\n",
    "https://jamboard.google.com/d/1zvyRx8BVp7OXSkLCs_jl3zeOyqap58J6X1HUboSv72M/edit?usp=sharing\n",
    "From Michał Klimas to Everyone:  01:18 PM\n",
    "def mean_test(column):\n",
    "    col_mean = column.mean()\n",
    "    return column < col_mean\n",
    "test_df.apply(lambda x: mean_test(x))\n",
    "From Michał Klimas to Everyone:  01:44 PM\n",
    "def modified_z_score_outlier(column):    \n",
    "    mad_column = median_abs_deviation(column)\n",
    "    median = np.median(column)\n",
    "    mad_score = np.abs(0.6745 * (column - median) / mad_column)\n",
    "    return mad_score > 3.5\n",
    "https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm\n",
    "From Iwona K to Everyone:  01:45 PM\n",
    "myślę żeby iść dalej\n",
    "From Michał Klimas to Everyone:  01:48 PM\n",
    "https://pastebin.com/ZyUM3dYf\n",
    "From Michał Klimas to Everyone:  01:54 PM\n",
    "https://chrisalbon.com/\n",
    "From Andrzej Stawicki to Everyone:  01:55 PM\n",
    "nie robiliśmy\n",
    "From Sławomir Kranc to Everyone:  02:26 PM\n",
    "28 chyba\n",
    "From Michał Klimas to Everyone:  02:30 PM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(houses_predictors, \n",
    "                                                    houses_target,\n",
    "                                                    train_size=0.7, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)\n",
    " \n",
    "def score_dataset(X_train, X_test, y_train, y_test):\n",
    "  regr_model = LinearRegression()\n",
    "  regr_model.fit(X_train, y_train)\n",
    "  preds = regr_model.predict(X_test)\n",
    "  return mean_absolute_error(y_test, preds)\n",
    "From Michał Klimas to Everyone:  02:40 PM\n",
    "Wracam za chwile\n",
    "jestem\n",
    "From Andrzej Stawicki to Everyone:  02:44 PM\n",
    "a co powinien zwrócić ten kod wyżej? jedną liczbę?\n",
    "From Michał Klimas to Everyone:  02:48 PM\n",
    "Jedna liczba\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error\n",
    "Możliwe jest zastosowanie multioutput, wtedy trzeba podać argument “raw_values”\n",
    "From Michał Klimas to Everyone:  03:09 PM\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html\n",
    "From Sławomir Kranc to Everyone:  03:30 PM\n",
    "Postępy u mnie: skończyłem te krótkie funkcje. Trochę czasu zajmuje zanim załapie się dokładnie jakie powinna przyjmować argumenty\n",
    "każda z metod\n",
    "From Michał Klimas to Everyone:  03:31 PM\n",
    "Ok, dziękuję\n",
    "From Sławomir Kranc to Everyone:  03:36 PM\n",
    "dobrze\n",
    "From Andrzej Stawicki to Everyone:  04:20 PM\n",
    "tak\n",
    "From Sławomir Kranc to Everyone:  04:20 PM\n",
    "ja jestem w trakcie :D\n",
    "From Andrzej Stawicki to Everyone:  04:20 PM\n",
    "udało się\n",
    "From Dawid Jaskulski to Everyone:  04:21 PM\n",
    "MAE for LinearRegression and RandomForestRegressor [279454.6, 179045.15]\n",
    "przy dropna axis 0\n",
    "From Andrzej Stawicki to Everyone:  04:23 PM\n",
    "możemy iść dalej:)\n",
    "From Dawid Jaskulski to Everyone:  04:23 PM\n",
    "Jeśli koledzy nie mają nic przeciwko to możemy iść dalej\n",
    "From Mikołaj Klawitter to Everyone:  04:24 PM\n",
    "zw\n",
    "From Andrzej Stawicki to Everyone:  04:25 PM\n",
    "Forest się dużo dłużej przelicza:)\n",
    "From Mikołaj Klawitter to Everyone:  04:26 PM\n",
    "jj\n",
    "From Michał Klimas to Everyone:  04:38 PM\n",
    "https://chrisalbon.com/machine_learning/preprocessing_structured_data/handling_outliers/\n",
    "From Michał Klimas to Everyone:  04:51 PM\n",
    "Wracam za chwile\n",
    "From Michał Klimas to Everyone:  05:05 PM\n",
    "Hasło do kursu ML:\n",
    "ML-niestacj-2021\n",
    "https://moodle.cdv.pl/course/view.php?id=1889\n",
    "From Sławomir Kranc to Everyone:  05:07 PM\n",
    "również potwierdzam\n",
    "From Michał Klimas to Everyone:  05:12 PM\n",
    "ML-niestacj-2021\n",
    "https://moodle.cdv.pl/course/view.php?id=1889\n",
    "From Sławomir Kranc to Everyone:  05:25 PM\n",
    "bardzo fajnie to wygląda\n",
    "From Iwona K to Everyone:  05:26 PM\n",
    "ja polecam yt:\n",
    "https://www.youtube.com/c/joshstarmer/featured\n",
    "From Dawid Jaskulski to Everyone:  05:32 PM\n",
    "trochę po za tematem ML: https://www.statystyczny.pl/\n",
    "statystyka w formie map myśli \n",
    "https://stackoverflow.com/questions/50473381/scikit-learns-labelbinarizer-vs-onehotencoder\n",
    "From Me to Everyone:  05:32 PM\n",
    "dziekuje! :)\n",
    "From Sławomir Kranc to Everyone:  05:35 PM\n",
    "https://datascience.stackexchange.com/questions/9443/when-to-use-one-hot-encoding-vs-labelencoder-vs-dictvectorizor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Machine_Learning_intro] *",
   "language": "python",
   "name": "conda-env-Machine_Learning_intro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
